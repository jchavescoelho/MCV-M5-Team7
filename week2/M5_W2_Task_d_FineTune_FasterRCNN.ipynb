{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "M5-W2-Task_d-FineTune_FasterRCNN",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cgz9hGTbGbq"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sAG_cKR0E97"
      },
      "source": [
        "# install dependencies: \n",
        "!pip install pyyaml==5.1\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version\n",
        "# opencv is pre-installed on colab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD2PfZLI1B-E"
      },
      "source": [
        "# install detectron2: (Colab has CUDA 10.1 + torch 1.8)\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "import torch\n",
        "assert torch.__version__.startswith(\"1.8\")   # need to manually install torch 1.8 if Colab changes its default version\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html\n",
        "# exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RR_R23N1ISL"
      },
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooa5QJ_5OiHV"
      },
      "source": [
        "| #Values | Names      | Description                                                                                                                |\n",
        "|---------|------------|----------------------------------------------------------------------------------------------------------------------------|\n",
        "| 1       | type       | Describes the type of object: 'Car', 'Van', 'Truck','Pedestrian', 'Person_sitting', 'Cyclist', 'Tram','Misc' or 'DontCare' |\n",
        "| 1       | truncated  | Float from 0 (non-truncated) to 1 (truncated),                                                                             |\n",
        "| 1       | occluded   | 0 = fully visible, 1 = partly occluded, 2 = largely occluded, 3 = unknown                                                  |\n",
        "| 1       | alpha      | Observation angle                                                                                                          |\n",
        "| 4       | bbox       | left, top, right, bottom pixel coordinates                                                                                 |\n",
        "| 3       | dimensions | 3D object dimensions: height, width, length (in meters)                                                                    |\n",
        "| 3       | location   | 3D object location x,y,z in camera coordinates (in meters)                                                                 |\n",
        "| 1       | rotation_y | Rotation ry around Y-axis in camera coordinates [-pi..pi]                                                                  |\n",
        "| 1       | score      | Only for results: Float, indicating confidence in detection, needed for p/r curves, higher is better.                      |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zyo7A4pwQYrS"
      },
      "source": [
        "Example:\n",
        "\n",
        "Car 0.60 3 -2.42 0.00 185.93 214.05 348.86 1.56 1.57 4.37 -6.96 1.73 7.83 -3.13"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckudxSCzOltV"
      },
      "source": [
        "# Register KITTI dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsU0sorWQtji"
      },
      "source": [
        "# if your dataset is in COCO format, this cell can be replaced by the following three lines:\n",
        "# from detectron2.data.datasets import register_coco_instances\n",
        "# register_coco_instances(\"my_dataset_train\", {}, \"json_annotation_train.json\", \"path/to/image/dir\")\n",
        "# register_coco_instances(\"my_dataset_val\", {}, \"json_annotation_val.json\", \"path/to/image/dir\")\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from detectron2.structures import BoxMode\n",
        "\n",
        "def get_kitti_dicts(kitti_dir, indices=range(500)):\n",
        "  classes = ('Car', 'Van', 'Truck','Pedestrian', 'Person_sitting', 'Cyclist', 'Tram','Misc', 'DontCare')\n",
        "  cols = ('type', 'truncated', 'occluded', 'alpha', 'left', 'top', 'right',\n",
        "      'bottom', 'height', 'width', 'length', 'x', 'y', 'z', 'rot_y','score')\n",
        "\n",
        "  record = {} #Dict with image info for the dataset\n",
        "\n",
        "  dataset_dicts = []\n",
        "  for idx in indices:\n",
        "      img_path = os.path.join(kitti_dir, 'data_object_image_2', 'training', 'image_2', str(idx).zfill(6)+'.png')\n",
        "      labels_path = os.path.join(kitti_dir, 'training', 'label_2', str(idx).zfill(6)+'.txt')\n",
        "      \n",
        "      height, width = cv2.imread(img_path).shape[:2]\n",
        "\n",
        "      record = {}\n",
        "      record[\"file_name\"] = img_path\n",
        "      record[\"image_id\"] = idx\n",
        "      record[\"height\"] = height\n",
        "      record[\"width\"] = width\n",
        "\n",
        "      objs = []\n",
        "\n",
        "      dtf = pd.read_csv(labels_path, delimiter=' ', names=cols)     \n",
        "      for i, row in dtf.iterrows():\n",
        "          # Accessing all available info\n",
        "          # obj = {\n",
        "          # 'type': row.type,\n",
        "          # 'truncated': row.truncated,\n",
        "          # 'occluded': row.occluded,\n",
        "          # 'alpha': row.alpha,\n",
        "          # 'bbox': (row.left, row.top, row.right, row.bottom),\n",
        "          # 'dims': (row.height, row.width, row.length),\n",
        "          # 'pos': (row.x, row.y, row.z),\n",
        "          # 'rot_y': row.rot_y,\n",
        "          # 'score': row.score\n",
        "          # }\n",
        "          # objs.append(obj)\n",
        "\n",
        "          # Add filters on truncated, occluded and maybe size?\n",
        "          obj = {\n",
        "            \"bbox\": [row.left, row.top, row.right, row.bottom],\n",
        "            \"bbox_mode\": BoxMode.XYXY_ABS,\n",
        "            \"category_id\": classes.index(row.type),\n",
        "          }\n",
        "          objs.append(obj)\n",
        "      record[\"annotations\"] = objs\n",
        "      dataset_dicts.append(record)\n",
        "      \n",
        "  return dataset_dicts\n",
        "  '''\n",
        "    dataset_dicts = []\n",
        "    for idx, v in enumerate(imgs_anns.values()):\n",
        "        record = {}\n",
        "        \n",
        "        filename = os.path.join(img_dir, v[\"filename\"])\n",
        "        height, width = cv2.imread(filename).shape[:2]\n",
        "        \n",
        "        record[\"file_name\"] = filename\n",
        "        record[\"image_id\"] = idx\n",
        "        record[\"height\"] = height\n",
        "        record[\"width\"] = width\n",
        "      \n",
        "        annos = v[\"regions\"]\n",
        "        objs = []\n",
        "        for _, anno in annos.items():\n",
        "            assert not anno[\"region_attributes\"]\n",
        "            anno = anno[\"shape_attributes\"]\n",
        "            px = anno[\"all_points_x\"]\n",
        "            py = anno[\"all_points_y\"]\n",
        "            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n",
        "            poly = [p for x in poly for p in x]\n",
        "\n",
        "            obj = {\n",
        "                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
        "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
        "                \"segmentation\": [poly],\n",
        "                \"category_id\": 0,\n",
        "            }\n",
        "            objs.append(obj)\n",
        "        record[\"annotations\"] = objs\n",
        "        dataset_dicts.append(record)\n",
        "    return dataset_dicts\n",
        "  '''\n",
        "\n",
        "# get_kitti_dicts('/content/drive/MyDrive/Datasets/KITTI')\n",
        "\n",
        "# for d in [\"train\", \"val\"]:\n",
        "#     DatasetCatalog.register(\"balloon_\" + d, lambda d=d: get_balloon_dicts(\"balloon/\" + d))\n",
        "#     MetadataCatalog.get(\"balloon_\" + d).set(thing_classes=[\"balloon\"])\n",
        "# balloon_metadata = MetadataCatalog.get(\"balloon_train\")\n",
        "ds_name = 'big-kitti'\n",
        "DatasetCatalog.register(\"small-kitti-train-big\", lambda : get_kitti_dicts('/content/drive/MyDrive/Datasets/KITTI', range(3500)))\n",
        "MetadataCatalog.get(\"small-kitti-train\").set(thing_classes=('Car', 'Van', 'Truck','Pedestrian', 'Person_sitting', 'Cyclist', 'Tram','Misc', 'DontCare') )\n",
        "\n",
        "DatasetCatalog.register(\"small-kitti-test-big\", lambda : get_kitti_dicts('/content/drive/MyDrive/Datasets/KITTI', range(3500, 4000)))\n",
        "MetadataCatalog.get(\"small-kitti-test-big\").set(thing_classes=('Car', 'Van', 'Truck','Pedestrian', 'Person_sitting', 'Cyclist', 'Tram','Misc', 'DontCare') )\n",
        "\n",
        "kitti_metadata = MetadataCatalog.get(\"small-kitti-train-big\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BijyoAp5fUhw"
      },
      "source": [
        "kitti_metadata = MetadataCatalog.get(\"small-kitti-train-big\")\n",
        "# Randomly visualize ds\n",
        "dataset_dicts = get_kitti_dicts('/content/drive/MyDrive/Datasets/KITTI')\n",
        "for d in random.sample(dataset_dicts, 3):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=kitti_metadata, scale=0.5)\n",
        "    out = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p5evmLCgNP4"
      },
      "source": [
        "# Train\n",
        "from detectron2.engine import DefaultTrainer\n",
        "classes = ('Car', 'Van', 'Truck','Pedestrian', 'Person_sitting', 'Cyclist', 'Tram','Misc', 'DontCare')\n",
        "\n",
        "mzoo_config_file = \"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(mzoo_config_file))\n",
        "cfg.DATASETS.TRAIN = (\"small-kitti-train-big\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(mzoo_config_file)  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 5\n",
        "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
        "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(classes)  \n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31XQdXeukd6b"
      },
      "source": [
        "# Inference should use the config with parameters that are used in training\n",
        "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Zk0NKRwkg1f"
      },
      "source": [
        "# Rnadomly visualize results\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "dataset_dicts = get_kitti_dicts('/content/drive/MyDrive/Datasets/KITTI')\n",
        "for d in random.sample(dataset_dicts, 1):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=kitti_metadata, \n",
        "                   scale=0.5, \n",
        "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
        "    )\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy0niyOUkvf1"
      },
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "\n",
        "evaluator = COCOEvaluator(\"small-kitti-test\", (\"bbox\",), False, output_dir=\"./output/\")\n",
        "val_loader = build_detection_test_loader(cfg,\"small-kitti-test\")\n",
        "print(inference_on_dataset(trainer.model, val_loader, evaluator))\n",
        "# another equivalent way to evaluate the model is to use `trainer.test`"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}